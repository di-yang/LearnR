---
title: "Result with weight; control for racial disparity; droped slope for highschool, PCP, unemployment; dif as dependent variable"
output:
  html_document:
    df_print: paged

---
# create weight manually
```{r}
rm(list = ls())
library(tidyverse)
library(readxl)
filenames <- list.files("./Ranked Measure Data2")
filenames
RMD <- data.frame(matrix(ncol = 0, nrow = 0))
for (filename in filenames){  
   yearnum <- gsub(".xls", "", filename)  
   RMD = RMD %>% bind_rows(assign(paste0("RMD",yearnum), read_excel(paste0("./Ranked Measure Data2/", filename), sheet="Ranked Measure Data", skip = 1) %>%
            mutate(year=yearnum) %>% 
            select(FIPS, year, YPLLRateLow, YPLLRateHigh)))
}

RMD$year=as.integer(RMD$year)
RMD=RMD %>% filter(substring(FIPS, 3,5)!="000")
RMD=RMD %>% drop_na(FIPS)
RMDwide= pivot_wider(RMD, id_cols = FIPS,  names_from = year, values_from = c(YPLLRateLow, YPLLRateHigh))

RMDwide$range15=(RMDwide$YPLLRateHigh_2015 - RMDwide$YPLLRateLow_2015)/(4*1.96)
RMDwide$irange15=1/RMDwide$range15
RMDwide$weight15=RMDwide$irange15 / sum(RMDwide$irange15, na.rm = TRUE)
sum(RMDwide$weight15 , na.rm = TRUE)

RMDwide$range16=(RMDwide$YPLLRateHigh_2016 - RMDwide$YPLLRateLow_2016)/(4*1.96)
RMDwide$irange16=1/RMDwide$range16
RMDwide$weight16=RMDwide$irange16 / sum(RMDwide$irange16, na.rm = TRUE)
sum(RMDwide$weight16, na.rm = TRUE)

RMDwide$range17=(RMDwide$YPLLRateHigh_2017 - RMDwide$YPLLRateLow_2017)/(4*1.96)
RMDwide$irange17=1/RMDwide$range17
RMDwide$weight17=RMDwide$irange17 / sum(RMDwide$irange17, na.rm = TRUE)
sum(RMDwide$weight17, na.rm = TRUE)

RMDwide$range18=(RMDwide$YPLLRateHigh_2018 - RMDwide$YPLLRateLow_2018)/(4*1.96)
RMDwide$irange18=1/RMDwide$range18
RMDwide$weight18=RMDwide$irange18 / sum(RMDwide$irange18, na.rm = TRUE)
sum(RMDwide$weight18, na.rm = TRUE)

RMDwide$range19=(RMDwide$YPLLRateHigh_2019 - RMDwide$YPLLRateLow_2019)/(4*1.96)
RMDwide$irange19=1/RMDwide$range19
RMDwide$weight19=RMDwide$irange19 / sum(RMDwide$irange19, na.rm = TRUE)
sum(RMDwide$weight19, na.rm = TRUE)

weight=RMDwide[c(1, 14, 17, 20, 23, 26)]
weight[is.na(weight)] = 0
weight$averweight=dim(weight)[1]*(weight$weight15 + weight$weight16 + weight$weight17 + weight$weight18 + weight$weight19)/5
weight=weight[c(1, 7)]
save(weight, file = "weight.RData")

load("analytic3FIPS.RData")
analyticnweight=merge(analytic3, weight, by.x="FIPS", by.y="FIPS")
analyticnweight=analyticnweight[-c(1)]
```

```{r}
library(tidyverse)
library(readxl)
library(corrplot)
library(weights)
rm(list = ls())
disparity=read_csv("./race.csv", col_types = "ccdddd")
disparity$FIPS=substr(disparity$GEO_ID, 10, 14)
disparity$blwt=disparity$S1701_C03_010E - disparity$S1701_C03_009E
disparity$hpnon=disparity$S1701_C03_016E - disparity$S1701_C03_017E
tomerge=disparity[c(7:9)]
load("analytic3FIPS.RData")
analyticwrace=merge(analytic3, tomerge, by.x="FIPS", by.y="FIPS")
load("weight.RData")
analyticwrace=merge(analyticwrace, weight, by.x="FIPS", by.y="FIPS")
analyticwrace = na.omit(analyticwrace)
analyticwrace = analyticwrace[-1]

tocor=analyticwrace[-c(23)]
weightonly=analyticwrace[c(23)]
tocor=as.matrix(tocor)

Mw=wtd.cor(tocor, weight = weightonly$averweight)
corrplot(Mw$correlation, method = 'color', order = 'alphabet')

#M = cor(analyticwrace)
#corrplot(M, method = 'number')
#corrplot(M, method = 'color', order = 'alphabet')
#corrplot(M)
```

# YPLL

```{r}
options(width = 300)
matrix(runif(100), ncol = 20)

library(caret)
library(xgboost)
library(doParallel)
library(pdp)
set.seed (1)
YPLLanalytic=analyticwrace[-c(2,3,4,23)]


nc = parallel::detectCores()  
cl = makePSOCKcluster(nc-1)   # Set number of cores equal to machine number minus one
registerDoParallel(cl)        #Set up parallel


inTraining = createDataPartition(YPLLanalytic$YPLLdif, p = .75, list = FALSE)
training = YPLLanalytic[ inTraining,]
testing  = YPLLanalytic[-inTraining,]
fitControl = trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                          allowParallel=TRUE
                          )

xgbGrid1 = expand.grid(nrounds = c(50, 100, 200), #200, 300
                       max_depth = c(1, 2, 3), #2, 4, 6
                       eta = c(0.01, 0.025, 0.05),  # 0.05, 0.075
                       gamma = 0,
                       colsample_bytree = c(0.8, 0.9, 1), #6, 7, 8
                       min_child_weight = 20,
                       subsample = c(0.8, 0.9, 1 )) #0.9, 1

xgbFit1 = train(YPLLdif ~ ., data = training,
                 method = "xgbTree", 
                 trControl = fitControl,
                 tuneGrid = xgbGrid1,
                weights = analyticwrace$averweight[inTraining],
                nthread=1,
                verbosity = 0
                )

stopCluster(cl)
plot(varImp(xgbFit1))
vi=varImp(xgbFit1)
vi$importance
xgbFit1
plot(xgbFit1)
```
```{r}
training_somecollegea = training
training_somecollegea$somecollegea = training$somecollegea*1.1
pred_0 = predict(object = xgbFit1,newdata = training)
hist(pred_0)
pred_1 = predict(object = xgbFit1,newdata = training_somecollegea)
delta_somecollegea = pred_1 - pred_0
hist(delta_somecollegea)
summary(delta_somecollegea)
summarytraining$somecollegea
summary(training$somecollegea)
# too few observations near the threshold
```


```{r }
xgb.pdp = list()
res.partialplot = list()
predvarls = list("somecollegea", "obesitya", "inactivitya", "uninsureda",  "unemploymenta", "blwt", "highschoola", "inactivityb", "obesityb", "highschoolb")
summary(YPLLanalytic$YPLLdif)

for (m in 1:length(predvarls)){
xgb.pdp[[m]] = 
  partial(
    object = xgbFit1,
    pred.var = predvarls[[m]],
    plot = FALSE,
    chull = TRUE,
    plot.engine = "ggplot2"
  )
res.partialplot[[m]] = plotPartial(xgb.pdp[[m]], rug =TRUE, train = training, ylim=c(99, 601) )
}

res.partialplot[[1]]
res.partialplot[[2]]
res.partialplot[[3]]
res.partialplot[[4]]
res.partialplot[[5]]
res.partialplot[[6]]
res.partialplot[[7]]
res.partialplot[[8]]
res.partialplot[[9]]
res.partialplot[[10]]
```

# mental
```{r}
options(width = 300)
matrix(runif(100), ncol = 20)

library(caret)
library(xgboost)
library(doParallel)
library(pdp)
set.seed (1)
mentalanalytic=analyticwrace[-c(1,3,4,23)]
nc = parallel::detectCores()  
cl = makePSOCKcluster(nc-1)   # Set number of cores equal to machine number minus one
registerDoParallel(cl)        #Set up parallel

inTraining = createDataPartition(mentalanalytic$mentaldif, p = .75, list = FALSE)
training = mentalanalytic[ inTraining,]
testing  = mentalanalytic[-inTraining,]
fitControl = trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                          allowParallel=TRUE
                          )

xgbGrid2 = expand.grid(nrounds = c(50, 100, 200), #200, 300
                       max_depth =c(1,2,3), #2, 4, 6
                       eta = c(0.01, 0.025),  # 0.05, 0.075
                       gamma = 0,
                       colsample_bytree = c(0.8,0.9, 1), #6, 7, 8
                       min_child_weight = 20,
                       subsample = c( 0.8, 0.9, 1 )) #0.9, 1

xgbFit2 = train(mentaldif ~ ., data = training,
                 method = "xgbTree", 
                 trControl = fitControl,
                 tuneGrid = xgbGrid2,
                weights = analyticwrace$averweight[inTraining],
                nthread=1,
                verbosity = 0
                )

stopCluster(cl)
plot(varImp(xgbFit2)) 
vi=varImp(xgbFit2)
vi$importance
xgbFit2
plot(xgbFit2)
```

```{r }
xgb.pdp2 = list()
res.partialplot2 = list()
predvarls2 = list("unemploymenta", "highschoolb", "obesitya", "inactivitya", "unemploymentb", "somecollegeb", "hpnon", "blwt", "uninsuredb", "uninsureda")
summary(mentalanalytic$mentaldif)

for (m in 1:length(predvarls2)){
xgb.pdp2[[m]] = 
  partial(
    object = xgbFit2,
    pred.var = predvarls2[[m]],
    plot = FALSE,
    chull = TRUE,
    plot.engine = "ggplot2"
  )
res.partialplot2[[m]] = plotPartial(xgb.pdp2[[m]], rug =TRUE, train = training, ylim=c(0.09,0.61))
}

res.partialplot2[[1]]
res.partialplot2[[2]]
res.partialplot2[[3]]
res.partialplot2[[4]]
res.partialplot2[[5]]
res.partialplot2[[6]]
res.partialplot2[[7]]
res.partialplot2[[8]]
res.partialplot2[[9]]
res.partialplot2[[10]]
```

# physical
```{r}
options(width = 300)
matrix(runif(100), ncol = 20)

library(caret)
library(xgboost)
library(doParallel)
library(pdp)
set.seed (1)
physicalanalytic=analyticwrace[-c(1,2,4,23)]

nc = parallel::detectCores()  
cl = makePSOCKcluster(nc-1)   # Set number of cores equal to machine number minus one
registerDoParallel(cl)        #Set up parallel

inTraining = createDataPartition(physicalanalytic$physicaldif, p = .75, list = FALSE)
training = physicalanalytic[ inTraining,]
testing  = physicalanalytic[-inTraining,]
fitControl = trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                          allowParallel=TRUE
                          )

xgbGrid3 = expand.grid(nrounds = c(50, 100, 200), #200, 300
                       max_depth = c(1,2,3), #2, 4, 6
                       eta = c(0.01, 0.025, 0.05),  # 0.05, 0.075
                       gamma = 0,
                       colsample_bytree = c( 0.8, 0.9, 1), #6, 7, 8
                       min_child_weight = 20,
                       subsample = c(0.8, 0.9, 1)) #0.9, 1

xgbFit3 = train(physicaldif ~ ., data = training,
                 method = "xgbTree", 
                 trControl = fitControl,
                 tuneGrid = xgbGrid3,
                weights = analyticwrace$averweight[inTraining],
                nthread=1,
                verbosity = 0
                )

stopCluster(cl)
plot(varImp(xgbFit3)) 
vi=varImp(xgbFit3) 
vi$importance
xgbFit3
plot(xgbFit3)
```

```{r }
xgb.pdp3 = list()
res.partialplot3 = list()
predvarls3 = list("somecollegea", "blwt", "inactivitya", "uninsureda", "childpovertya", "highschoolb", "obesityb", "highschoola", "hpnon", "unemploymenta")
summary(physicalanalytic$physicaldif)

for (m in 1:length(predvarls3)){
xgb.pdp3[[m]] = 
  partial(
    object = xgbFit3,
    pred.var = predvarls3[[m]],
    plot = FALSE,
    chull = TRUE,
    plot.engine = "ggplot2"
  )
res.partialplot3[[m]] = plotPartial(xgb.pdp3[[m]], rug =TRUE, train = training, ylim=c(-0.35, 0.45))
}

res.partialplot3[[1]]
res.partialplot3[[2]]
res.partialplot3[[3]]
res.partialplot3[[4]]
res.partialplot3[[5]]
res.partialplot3[[6]]
res.partialplot3[[7]]
res.partialplot3[[8]]
res.partialplot3[[9]]
res.partialplot3[[10]]
```

# fairpoor
```{r}
options(width = 300)
matrix(runif(100), ncol = 20)

library(caret)
library(xgboost)
library(doParallel)
library(pdp)
set.seed (1)
fairpooranalytic=analyticwrace[-c(1,2,3,23)]
nc = parallel::detectCores()  
cl = makePSOCKcluster(nc-1)   # Set number of cores equal to machine number minus one
registerDoParallel(cl)        #Set up parallel

inTraining = createDataPartition(fairpooranalytic$fairpoordif, p = .75, list = FALSE)
training = fairpooranalytic[ inTraining,]
testing  = fairpooranalytic[-inTraining,]
fitControl = trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 10,
                          allowParallel=TRUE
                          )

xgbGrid4 = expand.grid(nrounds = c(50, 100, 200), #200, 300
                       max_depth = c(1,2,3), #2, 4, 6
                       eta = c(0.01, 0.025, 0.5),  # 0.05, 0.075
                       gamma = 0,
                       colsample_bytree = c(0.8, 0.9, 1), #6, 7, 8
                       min_child_weight = 20,
                       subsample = c(0.8, 0.9, 1 )) #0.9, 1

xgbFit4 = train(fairpoordif ~ ., data = training,
                 method = "xgbTree", 
                 trControl = fitControl,
                 tuneGrid = xgbGrid4,
                weights = analyticwrace$averweight[inTraining],
                nthread=1,
                verbosity = 0
                )

stopCluster(cl)
plot(varImp(xgbFit4))
vi=varImp(xgbFit4)
vi$importance
xgbFit4
plot(xgbFit4)
```

```{r }
xgb.pdp4 = list()
res.partialplot4 = list()
predvarls4 = list("somecollegea", "inactivitya", "childpovertya", "uninsureda", "unemploymenta", "unemploymentb", "childpovertyb", "blwt", "inactivityb", "obesityb")
summary(fairpooranalytic$fairpoordif)

for (m in 1:length(predvarls4)){
xgb.pdp4[[m]] = 
  partial(
    object = xgbFit4,
    pred.var = predvarls4[[m]],
    plot = FALSE,
    chull = TRUE,
    plot.engine = "ggplot2"
  )
res.partialplot4[[m]] = plotPartial(xgb.pdp4[[m]], rug =TRUE, train = training, ylim=c(-2.5,3.1) )
}

res.partialplot4[[1]]
res.partialplot4[[2]]
res.partialplot4[[3]]
res.partialplot4[[4]]
res.partialplot4[[5]]
res.partialplot4[[6]]
res.partialplot4[[7]]
res.partialplot4[[8]]
res.partialplot4[[9]]
res.partialplot4[[10]]
```


